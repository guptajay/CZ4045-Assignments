{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90dfd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL = https://stackoverflow.com/questions/38826969/python-string-comparison-unexpected-results\n",
    "\n",
    "Article1 = \"\"\">>> '1.2.3'>'1.1.5'\n",
    "True\n",
    ">>> '1.1.3'>'1.1.5'\n",
    "False\n",
    ">>> '1.1.5'>'1.1.5'\n",
    "False\n",
    ">>> '1.1.7'>'1.1.5'\n",
    "True\n",
    ">>> '1.1.9'>'1.1.5'\n",
    "True\n",
    ">>> '1.1.10'>'1.1.5'\n",
    "False\n",
    ">>> '1.2'>'1.1.5'\n",
    "True\n",
    ">>> '1.2.9'>'1.1.5'\n",
    "True\n",
    ">>> '1.2.10'>'1.1.5'\n",
    "True\n",
    "Hi,\n",
    "\n",
    "I am trying to compare two strings as shown above. First of all, I am surprised that python comparing strings of numbers. firstly I thought that it will just compare lengths, but for different values it's giving exact values and I am astonished. But, for '1.1.10' > '1.1.5' it's false... i don't know why.... can anyone help...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc76939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL = https://stackoverflow.com/questions/1642028/what-is-the-operator-in-c-c\n",
    "Article2 = \"\"\"After reading Hidden Features and Dark Corners of C++/STL on comp.lang.c++.moderated, I was completely surprised that the following snippet compiled and worked in both Visual Studio 2008 and G++ 4.4.\n",
    "\n",
    "Here's the code:\n",
    "\n",
    "#include <stdio.h>\n",
    "int main()\n",
    "{\n",
    "    int x = 10;\n",
    "    while (x --> 0) // x goes to 0\n",
    "    {\n",
    "        printf(\"%d \", x);\n",
    "    }\n",
    "}\n",
    "Output:\n",
    "\n",
    "9 8 7 6 5 4 3 2 1 0\n",
    "I'd assume this is C, since it works in GCC as well. Where is this defined in the standard, and where has it come from?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0edbd8",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "### Article 1: \n",
    "1. Sentence capitalization is not consistent \n",
    "1. Sentences do not follow good grammar and punctuation\n",
    "1. Mistakes: \n",
    "- Capitalization is wrong in the words firstly and i\n",
    "- Comma is missing after values\n",
    "\n",
    "### Article 2:\n",
    "1. Good grammar and capitalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf8c3e",
   "metadata": {},
   "source": [
    "# General Observations of Writing:\n",
    "1. More Grammatical errors and informal style of writing\n",
    "2. Capitalization and punctuation are generally the most commonly made mistakes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a6662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize \n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e075bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e232d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencesArticle1 = nltk.word_tokenize(Article1)\n",
    "sentencesArticle2 = nltk.word_tokenize(Article2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c097f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.2.3'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "True\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.3'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "False\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.5'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "False\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.7'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "True\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.9'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "True\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.10'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "False\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.2'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "True\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.2.9'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "True\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.2.10'>'1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "True\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "Hi\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "\n",
      "\n",
      "\n",
      "Token:\n",
      "I\n",
      "Token:\n",
      "am\n",
      "Token:\n",
      "trying\n",
      "Token:\n",
      "to\n",
      "Token:\n",
      "compare\n",
      "Token:\n",
      "two\n",
      "Token:\n",
      "strings\n",
      "Token:\n",
      "as\n",
      "Token:\n",
      "shown\n",
      "Token:\n",
      "above\n",
      "Token:\n",
      ".\n",
      "Token:\n",
      "First\n",
      "Token:\n",
      "of\n",
      "Token:\n",
      "all\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "I\n",
      "Token:\n",
      "am\n",
      "Token:\n",
      "surprised\n",
      "Token:\n",
      "that\n",
      "Token:\n",
      "python\n",
      "Token:\n",
      "comparing\n",
      "Token:\n",
      "strings\n",
      "Token:\n",
      "of\n",
      "Token:\n",
      "numbers\n",
      "Token:\n",
      ".\n",
      "Token:\n",
      "firstly\n",
      "Token:\n",
      "I\n",
      "Token:\n",
      "thought\n",
      "Token:\n",
      "that\n",
      "Token:\n",
      "it\n",
      "Token:\n",
      "will\n",
      "Token:\n",
      "just\n",
      "Token:\n",
      "compare\n",
      "Token:\n",
      "lengths\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "but\n",
      "Token:\n",
      "for\n",
      "Token:\n",
      "different\n",
      "Token:\n",
      "values\n",
      "Token:\n",
      "it\n",
      "Token:\n",
      "'s\n",
      "Token:\n",
      "giving\n",
      "Token:\n",
      "exact\n",
      "Token:\n",
      "values\n",
      "Token:\n",
      "and\n",
      "Token:\n",
      "I\n",
      "Token:\n",
      "am\n",
      "Token:\n",
      "astonished\n",
      "Token:\n",
      ".\n",
      "Token:\n",
      "But\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "for\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.10\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "1.1.5\n",
      "Token:\n",
      "'\n",
      "Token:\n",
      "it\n",
      "Token:\n",
      "'s\n",
      "Token:\n",
      "false\n",
      "Token:\n",
      "...\n",
      "Token:\n",
      "i\n",
      "Token:\n",
      "do\n",
      "Token:\n",
      "n't\n",
      "Token:\n",
      "know\n",
      "Token:\n",
      "why\n",
      "Token:\n",
      "....\n",
      "Token:\n",
      "can\n",
      "Token:\n",
      "anyone\n",
      "Token:\n",
      "help\n",
      "Token:\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(Article1)\n",
    "\n",
    "# Token and Tag\n",
    "for token in doc:\n",
    "    print('Token:')\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ace0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:\n",
      "After\n",
      "Token:\n",
      "reading\n",
      "Token:\n",
      "Hidden\n",
      "Token:\n",
      "Features\n",
      "Token:\n",
      "and\n",
      "Token:\n",
      "Dark\n",
      "Token:\n",
      "Corners\n",
      "Token:\n",
      "of\n",
      "Token:\n",
      "C++/STL\n",
      "Token:\n",
      "on\n",
      "Token:\n",
      "comp.lang.c++.moderated\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "I\n",
      "Token:\n",
      "was\n",
      "Token:\n",
      "completely\n",
      "Token:\n",
      "surprised\n",
      "Token:\n",
      "that\n",
      "Token:\n",
      "the\n",
      "Token:\n",
      "following\n",
      "Token:\n",
      "snippet\n",
      "Token:\n",
      "compiled\n",
      "Token:\n",
      "and\n",
      "Token:\n",
      "worked\n",
      "Token:\n",
      "in\n",
      "Token:\n",
      "both\n",
      "Token:\n",
      "Visual\n",
      "Token:\n",
      "Studio\n",
      "Token:\n",
      "2008\n",
      "Token:\n",
      "and\n",
      "Token:\n",
      "G++\n",
      "Token:\n",
      "4.4\n",
      "Token:\n",
      ".\n",
      "Token:\n",
      "\n",
      "\n",
      "\n",
      "Token:\n",
      "Here\n",
      "Token:\n",
      "'s\n",
      "Token:\n",
      "the\n",
      "Token:\n",
      "code\n",
      "Token:\n",
      ":\n",
      "Token:\n",
      "\n",
      "\n",
      "\n",
      "Token:\n",
      "#\n",
      "Token:\n",
      "include\n",
      "Token:\n",
      "<\n",
      "Token:\n",
      "stdio.h\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "int\n",
      "Token:\n",
      "main\n",
      "Token:\n",
      "(\n",
      "Token:\n",
      ")\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "{\n",
      "Token:\n",
      "\n",
      "    \n",
      "Token:\n",
      "int\n",
      "Token:\n",
      "x\n",
      "Token:\n",
      "=\n",
      "Token:\n",
      "10\n",
      "Token:\n",
      ";\n",
      "Token:\n",
      "\n",
      "    \n",
      "Token:\n",
      "while\n",
      "Token:\n",
      "(\n",
      "Token:\n",
      "x\n",
      "Token:\n",
      "--\n",
      "Token:\n",
      ">\n",
      "Token:\n",
      "0\n",
      "Token:\n",
      ")\n",
      "Token:\n",
      "//\n",
      "Token:\n",
      "x\n",
      "Token:\n",
      "goes\n",
      "Token:\n",
      "to\n",
      "Token:\n",
      "0\n",
      "Token:\n",
      "\n",
      "    \n",
      "Token:\n",
      "{\n",
      "Token:\n",
      "\n",
      "        \n",
      "Token:\n",
      "printf(\"%d\n",
      "Token:\n",
      "\"\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "x\n",
      "Token:\n",
      ")\n",
      "Token:\n",
      ";\n",
      "Token:\n",
      "\n",
      "    \n",
      "Token:\n",
      "}\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "}\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "Output\n",
      "Token:\n",
      ":\n",
      "Token:\n",
      "\n",
      "\n",
      "\n",
      "Token:\n",
      "9\n",
      "Token:\n",
      "8\n",
      "Token:\n",
      "7\n",
      "Token:\n",
      "6\n",
      "Token:\n",
      "5\n",
      "Token:\n",
      "4\n",
      "Token:\n",
      "3\n",
      "Token:\n",
      "2\n",
      "Token:\n",
      "1\n",
      "Token:\n",
      "0\n",
      "Token:\n",
      "\n",
      "\n",
      "Token:\n",
      "I\n",
      "Token:\n",
      "'d\n",
      "Token:\n",
      "assume\n",
      "Token:\n",
      "this\n",
      "Token:\n",
      "is\n",
      "Token:\n",
      "C\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "since\n",
      "Token:\n",
      "it\n",
      "Token:\n",
      "works\n",
      "Token:\n",
      "in\n",
      "Token:\n",
      "GCC\n",
      "Token:\n",
      "as\n",
      "Token:\n",
      "well\n",
      "Token:\n",
      ".\n",
      "Token:\n",
      "Where\n",
      "Token:\n",
      "is\n",
      "Token:\n",
      "this\n",
      "Token:\n",
      "defined\n",
      "Token:\n",
      "in\n",
      "Token:\n",
      "the\n",
      "Token:\n",
      "standard\n",
      "Token:\n",
      ",\n",
      "Token:\n",
      "and\n",
      "Token:\n",
      "where\n",
      "Token:\n",
      "has\n",
      "Token:\n",
      "it\n",
      "Token:\n",
      "come\n",
      "Token:\n",
      "from\n",
      "Token:\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(Article2)\n",
    "\n",
    "# Token and Tag\n",
    "for token in doc:\n",
    "    print('Token:')\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1312df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> PUNCT > PUNCT > X ' PART 1.2.3'>'1.1.5 NUM ' PUNCT \n",
      " SPACE True PROPN \n",
      " SPACE > PUNCT > PUNCT > PUNCT ' PUNCT 1.1.3'>'1.1.5 NUM ' PUNCT \n",
      " SPACE False PROPN \n",
      " SPACE > PUNCT > PUNCT > PUNCT ' PUNCT 1.1.5'>'1.1.5 NUM ' PUNCT \n",
      " SPACE False PROPN \n",
      " SPACE > PUNCT > PUNCT > X ' PUNCT 1.1.7'>'1.1.5 NUM ' PUNCT \n",
      " SPACE True PROPN \n",
      " SPACE > PUNCT > PUNCT > X ' PART 1.1.9'>'1.1.5 NUM ' PUNCT \n",
      " SPACE True PROPN \n",
      " SPACE > PUNCT > PUNCT > PUNCT ' PUNCT 1.1.10'>'1.1.5 PRON ' PUNCT \n",
      " SPACE False PROPN \n",
      " SPACE > PUNCT > PUNCT > PUNCT ' PUNCT 1.2'>'1.1.5 NUM ' PUNCT \n",
      " SPACE True PROPN \n",
      " SPACE > PUNCT > X > X ' PART 1.2.9'>'1.1.5 NUM ' PUNCT \n",
      " SPACE True PROPN \n",
      " SPACE > PUNCT > PUNCT > PUNCT ' PUNCT 1.2.10'>'1.1.5 PROPN ' PART \n",
      " SPACE True ADJ \n",
      " SPACE Hi INTJ , PUNCT \n",
      "\n",
      " SPACE I PRON am AUX trying VERB to PART compare VERB two NUM strings NOUN as ADP shown VERB above ADV . PUNCT First ADV of ADP all DET , PUNCT I PRON am AUX surprised ADJ that SCONJ python PROPN comparing VERB strings NOUN of ADP numbers NOUN . PUNCT firstly ADV I PRON thought VERB that SCONJ it PRON will AUX just ADV compare VERB lengths NOUN , PUNCT but CCONJ for ADP different ADJ values NOUN it PRON 's AUX giving VERB exact ADJ values NOUN and CCONJ I PRON am AUX astonished VERB . PUNCT But CCONJ , PUNCT for ADP ' PUNCT 1.1.10 PROPN ' PUNCT > SYM ' PUNCT 1.1.5 NUM ' PUNCT it PRON 's VERB false ADJ ... PUNCT i PRON do AUX n't PART know VERB why ADV .... PUNCT can AUX anyone PRON help VERB ... PUNCT "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "doc = nlp(Article1)\n",
    "\n",
    "# Token and Tag\n",
    "for token in doc:\n",
    "    print(token, token.pos_,\"\",end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d1275",
   "metadata": {},
   "source": [
    "mistakes: PART\tparticle\t*â€™s, not,*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c0aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADP reading VERB Hidden PROPN Features PROPN and CCONJ Dark PROPN Corners PROPN of ADP C++/STL PROPN on ADP comp.lang.c++.moderated VERB , PUNCT I PRON was AUX completely ADV surprised ADJ that SCONJ the DET following VERB snippet NOUN compiled VERB and CCONJ worked VERB in ADP both DET Visual PROPN Studio PROPN 2008 NUM and CCONJ G++ PROPN 4.4 NUM . PUNCT \n",
      "\n",
      " SPACE Here ADV 's AUX the DET code NOUN : PUNCT \n",
      "\n",
      " SPACE # NOUN include VERB < X stdio.h PROPN > PUNCT \n",
      " SPACE int NOUN main ADJ ( PUNCT ) PUNCT \n",
      " SPACE { PUNCT \n",
      "     SPACE int NOUN x SYM = NOUN 10 NUM ; PUNCT \n",
      "     SPACE while SCONJ ( PUNCT x X -- PUNCT > PUNCT 0 NUM ) PUNCT // PUNCT x X goes VERB to ADP 0 NUM \n",
      "     SPACE { PUNCT \n",
      "         SPACE printf(\"%d PROPN \" PUNCT , PUNCT x X ) PUNCT ; PUNCT \n",
      "     SPACE } PUNCT \n",
      " SPACE } PUNCT \n",
      " SPACE Output NOUN : PUNCT \n",
      "\n",
      " SPACE 9 NUM 8 NUM 7 NUM 6 NUM 5 NUM 4 NUM 3 NUM 2 NUM 1 NUM 0 NUM \n",
      " SPACE I PRON 'd AUX assume VERB this DET is AUX C NOUN , PUNCT since SCONJ it PRON works VERB in ADP GCC PROPN as ADV well ADV . PUNCT Where ADV is AUX this DET defined VERB in ADP the DET standard NOUN , PUNCT and CCONJ where ADV has AUX it PRON come VERB from ADP ? PUNCT "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "doc = nlp(Article2)\n",
    "\n",
    "# Token and Tag\n",
    "for token in doc:\n",
    "    print(token,token.pos_,\"\",end = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
